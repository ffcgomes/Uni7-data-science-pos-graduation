{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "20news-extraction-tutorial-sklearn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFbwmg7Mvek3"
      },
      "source": [
        "#Working With Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_aYWXiHvek5"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jo1kYOsvek6"
      },
      "source": [
        "##A fim de obter tempos de execução mais rápidos para este primeiro exemplo, trabalharemos em um conjunto de dados parcial com apenas 4 categorias das 20 disponíveis no conjunto de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XyzHeXJvek6"
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "              'comp.graphics', 'sci.med']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZptBwKkvek7"
      },
      "source": [
        "##Agora podemos carregar a lista de arquivos que correspondem a essas categorias da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YE4DZo4vek7",
        "outputId": "2392cdc2-379a-4430-cd30-e215f19c5a84"
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train',\n",
        "     categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iurieG0_vek8",
        "outputId": "bacd672b-c11e-47d4-834d-87ec78d62a94"
      },
      "source": [
        "type(twenty_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Raw8XKvek9"
      },
      "source": [
        "##O conjunto de dados retornado é um \"grupo\" (bunch) de scikit-learn: um objeto de suporte simples com campos que podem ser acessados ​​como chaves python dict ou atributos de objeto por conveniência, por exemplo, o target_names contém a lista dos nomes de categoria solicitados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "750wuV7Tvek9",
        "outputId": "56fa9e70-9ec8-4ca8-92a6-aa0d722e5e09"
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFP7ZRFbvek-"
      },
      "source": [
        "##Os próprios arquivos são carregados na memória no atributo \"data\". Para referência, os nomes dos arquivos também estão disponíveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ultXuZxbvek-",
        "outputId": "242150de-c561-47c2-8acc-11fcf7720bb2"
      },
      "source": [
        "len(twenty_train.data)\n",
        "len(twenty_train.filenames)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbOOh0G-vek-"
      },
      "source": [
        "##Vamos imprimir as primeiras linhas do primeiro arquivo carregado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJJSLgCGvek_",
        "outputId": "e7f647cc-8eab-4479-8ed5-1db1036b3140"
      },
      "source": [
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: sd345@city.ac.uk (Michael Collier)\n",
            "Subject: Converting images to HP LaserJet III?\n",
            "Nntp-Posting-Host: hampton\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhbVw_k3vek_",
        "outputId": "5b8e0d6d-a922-410d-f382-97337f87dedd"
      },
      "source": [
        "print(twenty_train.target_names[twenty_train.target[0]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comp.graphics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG7V7C5Qvek_"
      },
      "source": [
        "##Algoritmos de aprendizado supervisionado exigirão um rótulo de categoria para cada documento no conjunto de treinamento. Nesse caso, a categoria é o nome do grupo de notícias que também é o nome da pasta que contém os documentos individuais. Por motivos de velocidade e eficiência de espaço, o scikit-learn carrega o atributo target como uma matriz de inteiros que corresponde ao índice do nome da categoria na lista target_names. O ID de categoria inteira de cada amostra é armazenado no atributo de destino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_XCljp-velA",
        "outputId": "f87f8d2e-bf53-4925-fc99-f691d6cfe0d8"
      },
      "source": [
        "twenty_train.target[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO-IFiIovelA"
      },
      "source": [
        "##É possível recuperar os nomes das categorias da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BGrGkcRvelA",
        "outputId": "25fb183e-d7e6-428c-ae94-eab63d3f00ef"
      },
      "source": [
        "for t in twenty_train.target[:10]:\n",
        "     print(twenty_train.target_names[t])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comp.graphics\n",
            "comp.graphics\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulsWoT_QvelA"
      },
      "source": [
        "##Você deve ter notado que as amostras foram embaralhadas aleatoriamente quando chamamos fetch_20newsgroups (..., shuffle = True, random_state = 42): isso é útil se você deseja selecionar apenas um subconjunto de amostras para treinar rapidamente um modelo e obter um primeiro ideia dos resultados antes de treinar novamente no conjunto de dados completo mais tarde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bC_iJNsvelB"
      },
      "source": [
        "#Extracting features from text files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukw9nue7velB"
      },
      "source": [
        "##Para realizar o aprendizado de máquina em documentos de texto, primeiro precisamos transformar o conteúdo do texto em vetores de recursos numéricos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-i0e-6velB"
      },
      "source": [
        "##Sacos de palavras\n",
        "\n",
        "A maneira mais intuitiva de fazer isso é usar uma representação de sacos de palavras: Atribua um ID de número inteiro fixo para cada palavra que ocorre em qualquer documento do conjunto de treinamento (por exemplo, construindo um dicionário de palavras para índices inteiros). Para cada documento #i, conte o número de ocorrências de cada palavra w e armazene-o em X [i, j] como o valor da característica #j onde j é o índice da palavra w no dicionário. A representação dos pacotes de palavras implica que n_features é o número de palavras distintas no corpus: esse número é normalmente maior do que 100.000. Se n_samples == 10000, o armazenamento de X como uma matriz NumPy do tipo float32 exigiria 10000 x 100000 x 4 bytes = 4 GB em RAM, o que dificilmente é gerenciável nos computadores de hoje. Felizmente, a maioria dos valores em X serão zeros, pois, para um determinado documento, serão usados ​​menos de alguns milhares de palavras distintas. Por esse motivo, dizemos que pacotes de palavras são tipicamente conjuntos de dados esparsos de alta dimensão. Podemos economizar muita memória armazenando apenas as partes diferentes de zero dos vetores de recursos na memória. As matrizes scipy.sparse são estruturas de dados que fazem exatamente isso, e o scikit-learn tem suporte integrado para essas estruturas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbRTrm53velB"
      },
      "source": [
        "##Tokenização de texto\n",
        "\n",
        "Com scikit-learn Pré-processamento de texto, tokenização e filtragem de palavras irrelevantes estão todos incluídos no CountVectorizer, que cria um dicionário de recursos e transforma documentos em vetores de recursos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muo1ikGXvelC",
        "outputId": "31c593c4-3cd5-4f27-facf-bdd6d234a4b9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmuNRzsdvelC"
      },
      "source": [
        "##CountVectorizer suporta contagens de N-gramas de palavras ou caracteres consecutivos. Uma vez ajustado, o vetorizador construiu um dicionário de índices de recursos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gbVmGhBvelC",
        "outputId": "2f4b3709-993b-4606-bb0c-024798234c68"
      },
      "source": [
        "count_vect.vocabulary_.get(u'algorithm')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mbWWhXZvelC"
      },
      "source": [
        "##O valor do índice de uma palavra no vocabulário está relacionado à sua frequência em todo o corpus de treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNh89v5VvelD"
      },
      "source": [
        "##De ocorrências a frequências\n",
        "\n",
        "A contagem de ocorrências é um bom começo, mas há um problema: documentos mais longos terão valores médios de contagem mais altos do que documentos mais curtos, embora possam falar sobre os mesmos tópicos. Para evitar essas discrepâncias em potencial, é suficiente dividir o número de ocorrências de cada palavra em um documento pelo número total de palavras no documento: esses novos recursos são chamados de tf para Frequências de termo. Outro refinamento além do tf é reduzir os pesos das palavras que ocorrem em muitos documentos no corpus e, portanto, são menos informativas do que aquelas que ocorrem apenas em uma parte menor do corpus. Essa redução é chamada de tf – idf para “Frequência do termo vezes frequência inversa do documento”. Tanto tf quanto tf – idf podem ser calculados da seguinte maneira usando TfidfTransformer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TllqVKcvelD",
        "outputId": "e699f2ef-6ba5-450e-e8e2-0c508b5a30c6"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "X_train_tf.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoVeD9M5velD"
      },
      "source": [
        "##No código de exemplo acima, primeiro usamos o método fit (..) para ajustar nosso estimador aos dados e, em segundo lugar, o método transform (..) para transformar nossa matriz de contagem em uma representação tf-idf. Essas duas etapas podem ser combinadas para atingir o mesmo resultado final mais rápido, ignorando o processamento redundante. Isso é feito usando o método fit_transform (..) conforme mostrado abaixo e conforme mencionado na nota da seção anterior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdn3JBJyvelD",
        "outputId": "926398c0-0d44-4d71-f764-ecb811464725"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1zUoA49velE"
      },
      "source": [
        "#Treinando um classificador \n",
        "\n",
        "Agora que temos nossos recursos, podemos treinar um classificador para tentar prever a categoria de uma postagem. Vamos começar com um classificador Bayes ingênuo, que fornece uma boa base para esta tarefa. O scikit-learn inclui várias variantes desse classificador; o mais adequado para contagem de palavras é a variante multinomial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FGwEm5evelE"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh7tURYvelE"
      },
      "source": [
        "##Para tentar prever o resultado em um novo documento, precisamos extrair os recursos usando quase a mesma cadeia de extração de recursos de antes. A diferença é que chamamos transform em vez de fit_transform nos transformadores, uma vez que eles já foram ajustados ao conjunto de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awtBwhs3velE",
        "outputId": "ebc689b1-ee34-4f0b-ca70-34d26ff77fea"
      },
      "source": [
        "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'God is love' => soc.religion.christian\n",
            "'OpenGL on the GPU is fast' => comp.graphics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7fBYZozvelF"
      },
      "source": [
        "#Building a pipeline\n",
        "\n",
        "In order to make the vectorizer => transformer => classifier easier to work with, scikit-learn provides a Pipeline class that behaves like a compound classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plowFi7VvelF"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQzm70lvelG"
      },
      "source": [
        "##Os nomes vect, tfidf e clf (classificador) são arbitrários. Iremos usá-los para realizar o grid search para hiperparâmetros adequados abaixo. Agora podemos treinar o modelo com um único comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNy5coVKvelG",
        "outputId": "c24b50db-6603-4ece-ca0d-32eb15316ac2"
      },
      "source": [
        "text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KblklaRpvelG"
      },
      "source": [
        "#Avaliação do desempenho no conjunto de teste\n",
        "\n",
        "Avaliar a precisão preditiva do modelo é igualmente fácil:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qJTdpqlvelG",
        "outputId": "8d6614c6-78b7-405c-a3da-a1ebe49d9fef"
      },
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test',\n",
        "    categories=categories, shuffle=True, random_state=42)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348868175765646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smYk584fvelG"
      },
      "source": [
        "##Atingimos 83,5% de precisão. Vamos ver se podemos fazer melhor com uma máquina de vetores de suporte linear (SVM), que é amplamente considerada como um dos melhores algoritmos de classificação de texto (embora também seja um pouco mais lenta do que o ingênuo Bayes). Podemos mudar o aluno simplesmente conectando um objeto classificador diferente em nosso pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpCCKPI-velH",
        "outputId": "6a200143-3742-40a1-8bfa-e24d6cde1791"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\r\n",
        "text_clf = Pipeline([\r\n",
        "    ('vect', CountVectorizer()),\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\r\n",
        "                          alpha=1e-3, random_state=42,\r\n",
        "                          max_iter=5, tol=None)),\r\n",
        "])\r\n",
        "\r\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)\r\n",
        "\r\n",
        "predicted = text_clf.predict(docs_test)\r\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9101198402130493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD4iIsABM4nU"
      },
      "source": [
        "##Alcançamos 91,3% de precisão usando o SVM. O scikit-learn fornece mais utilitários para uma análise de desempenho mais detalhada dos resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EG7O9uuM8kM",
        "outputId": "046ef4d2-26cc-478c-fa46-6ad42af8d352"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "print(metrics.classification_report(twenty_test.target, predicted,\r\n",
        "    target_names=twenty_test.target_names))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.95      0.80      0.87       319\n",
            "         comp.graphics       0.87      0.98      0.92       389\n",
            "               sci.med       0.94      0.89      0.91       396\n",
            "soc.religion.christian       0.90      0.95      0.93       398\n",
            "\n",
            "              accuracy                           0.91      1502\n",
            "             macro avg       0.91      0.91      0.91      1502\n",
            "          weighted avg       0.91      0.91      0.91      1502\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqo-2QJsNBPr",
        "outputId": "fad6cda2-e4d7-49a6-f4db-5055770b26c0"
      },
      "source": [
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[256,  11,  16,  36],\n",
              "       [  4, 380,   3,   2],\n",
              "       [  5,  35, 353,   3],\n",
              "       [  5,  11,   4, 378]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygrs8MRoNIWt"
      },
      "source": [
        "##Como esperado, a matriz de confusão mostra que as postagens de grupos de notícias sobre ateísmo e cristianismo são mais freqüentemente confundidas umas com as outras do que com computação gráfica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GZJjyUXNbrA"
      },
      "source": [
        "#Ajuste de parâmetro usando Grid Search\r\n",
        "\r\n",
        "##Já encontramos alguns parâmetros, como use_idf no TfidfTransformer. Classificadores tendem a ter muitos parâmetros também; por exemplo, MultinomialNB inclui um parâmetro de suavização alfa e SGDClassifier tem um parâmetro de penalidade alfa e perda configurável e termos de penalidade na função objetivo (consulte a documentação do módulo ou use a função de ajuda Python para obter uma descrição destes). Em vez de ajustar os parâmetros dos vários componentes da cadeia, é possível executar uma pesquisa exaustiva dos melhores parâmetros em uma grade de valores possíveis. Testamos todos os classificadores em palavras ou bigramas, com ou sem idf, e com um parâmetro de penalidade de 0,01 ou 0,001 para o SVM linear:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98LidLb8NDfb"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "parameters = {\r\n",
        "    'vect__ngram_range': [(1, 1), (1, 2)],\r\n",
        "    'tfidf__use_idf': (True, False),\r\n",
        "    'clf__alpha': (1e-2, 1e-3),\r\n",
        "}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTDD-MqzN0Rs"
      },
      "source": [
        "##Obviamente, uma pesquisa tão exaustiva pode ser cara. Se tivermos vários núcleos de CPU à nossa disposição, podemos dizer ao pesquisador da grade para tentar essas oito combinações de parâmetros em paralelo com o parâmetro n_jobs. Se dermos a este parâmetro um valor de -1, a pesquisa em grade detectará quantos núcleos estão instalados e usará todos eles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irzwqxYfNxwM"
      },
      "source": [
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWhEXvp3OH14"
      },
      "source": [
        "##A instância do Grid Search se comporta como um modelo normal de scikit-learn. Vamos realizar a pesquisa em um subconjunto menor dos dados de treinamento para acelerar o cálculo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA7GOVpsOEMg"
      },
      "source": [
        "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H0X6RxLOYMg"
      },
      "source": [
        "##O resultado de chamar o ajuste em um objeto GridSearchCV é um classificador que podemos usar para prever:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nDDDTLiGOUgG",
        "outputId": "78df8c01-a725-4126-c80e-1d5e250af8d0"
      },
      "source": [
        "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'soc.religion.christian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmj6coWFOkrI"
      },
      "source": [
        "##Os atributos best_score_ e best_params_ do objeto armazenam a melhor pontuação média e a configuração de parâmetros correspondente a essa pontuação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZn14zcFOh7w",
        "outputId": "c4bd664e-5d30-4310-f077-798971f38e6b"
      },
      "source": [
        "gs_clf.best_score_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9175000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-rLT35OuRJ",
        "outputId": "fffdaabc-7772-4c94-b7a2-c2b46e4c6a05"
      },
      "source": [
        "for param_name in sorted(parameters.keys()):\r\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clf__alpha: 0.001\n",
            "tfidf__use_idf: True\n",
            "vect__ngram_range: (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbCW10tLO6rW"
      },
      "source": [
        "##Um resumo mais detalhado da pesquisa está disponível abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-x_XtssOx5v",
        "outputId": "a8022411-1a39-499c-e727-ecab4c2a126b"
      },
      "source": [
        "gs_clf.cv_results_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.16758294, 0.59642363, 0.16298051, 0.58901219, 0.16380959,\n",
              "        0.60236235, 0.15822172, 0.55431924]),\n",
              " 'mean_score_time': array([0.03162732, 0.06432204, 0.03053703, 0.06171703, 0.03202624,\n",
              "        0.06665058, 0.03196502, 0.05840034]),\n",
              " 'mean_test_score': array([0.8925, 0.8975, 0.7625, 0.7675, 0.9175, 0.9125, 0.7925, 0.83  ]),\n",
              " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_tfidf__use_idf': masked_array(data=[True, True, False, False, True, True, False, False],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 1), (1, 2), (1, 1), (1, 2), (1, 1),\n",
              "                    (1, 2)],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__alpha': 0.01,\n",
              "   'tfidf__use_idf': True,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}],\n",
              " 'rank_test_score': array([4, 3, 8, 7, 1, 2, 6, 5], dtype=int32),\n",
              " 'split0_test_score': array([0.9   , 0.8875, 0.7   , 0.6875, 0.9   , 0.9125, 0.825 , 0.8   ]),\n",
              " 'split1_test_score': array([0.8625, 0.85  , 0.7125, 0.7   , 0.9   , 0.8875, 0.7625, 0.8   ]),\n",
              " 'split2_test_score': array([0.8875, 0.9   , 0.775 , 0.8   , 0.925 , 0.8875, 0.75  , 0.8   ]),\n",
              " 'split3_test_score': array([0.9125, 0.925 , 0.8   , 0.8125, 0.925 , 0.925 , 0.8   , 0.85  ]),\n",
              " 'split4_test_score': array([0.9   , 0.925 , 0.825 , 0.8375, 0.9375, 0.95  , 0.825 , 0.9   ]),\n",
              " 'std_fit_time': array([0.00680885, 0.01712363, 0.01355166, 0.01500334, 0.01355673,\n",
              "        0.0165365 , 0.0129337 , 0.06860002]),\n",
              " 'std_score_time': array([0.00270452, 0.00739093, 0.00321958, 0.00722775, 0.0030164 ,\n",
              "        0.00717467, 0.00290727, 0.01391686]),\n",
              " 'std_test_score': array([0.01695582, 0.02783882, 0.04873397, 0.06154267, 0.015     ,\n",
              "        0.02371708, 0.03122499, 0.04      ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRKfJ-zdPFIi"
      },
      "source": [
        "##O parâmetro cv_results_ pode ser facilmente importado para o pandas como um DataFrame para inspeção posterior."
      ]
    }
  ]
}