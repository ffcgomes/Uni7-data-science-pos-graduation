{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenization-example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-QDnk15vl_C"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nb5A2Bxv2bb",
        "outputId": "84a20dcf-3cb2-4975-8ee5-6d514a1f1c05"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXCMQxQbvjMm",
        "outputId": "f1e25b18-6c66-4e59-e017-43cf3063d564"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\r\n",
        "\r\n",
        "# Texto\r\n",
        "frase = \"Aprendendo processamento linguagem natural. Python e NLTK facilitam nossa vida!\"\r\n",
        "\r\n",
        "# Tokenization em sentenças\r\n",
        "sent_tokens = sent_tokenize(frase)\r\n",
        "print(sent_tokens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Aprendendo processamento linguagem natural.', 'Python e NLTK facilitam nossa vida!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLmmRWBVwp60",
        "outputId": "b2092ebc-f63a-4cb5-e782-18ab6ec7746a"
      },
      "source": [
        "word_tokens = word_tokenize(frase)\r\n",
        "print(word_tokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Aprendendo', 'processamento', 'linguagem', 'natural', '.', 'Python', 'e', 'NLTK', 'facilitam', 'nossa', 'vida', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7FDQq1IxFQ9"
      },
      "source": [
        "##English Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIWS-wdoxO9K",
        "outputId": "39dc8c5b-5114-4b11-e6a0-ae0a0475bb16"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnxDvN6IxEGl",
        "outputId": "8c547f87-47bd-4961-dc09-6d56f91a855f"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "english_stops = set(stopwords.words('english'))\r\n",
        "\r\n",
        "print(english_stops)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'itself', \"aren't\", 'mustn', 'be', 'hadn', 'are', 'should', 'into', 'again', 'few', 'there', 'isn', \"haven't\", \"hasn't\", 'now', 'where', 'd', 'until', 'my', 'to', 'on', 'you', 'have', 'yours', 'has', 'll', \"you're\", \"you'd\", 'after', 's', 'she', \"that'll\", 'theirs', \"won't\", \"wasn't\", 'up', 'other', 'down', 'y', \"wouldn't\", 'all', 'it', 'both', 'because', 'ourselves', 'having', 'shan', 'aren', 'for', 'an', 'how', 'and', 'we', 'herself', 'were', 'when', 'against', 'mightn', 'me', 'if', 'his', 'any', \"weren't\", \"you've\", 'but', 'who', \"you'll\", 'during', 'was', 'why', 'of', 'the', 'in', 'nor', 'with', 'didn', 'our', \"shouldn't\", \"isn't\", 'than', 'this', 'here', 'm', \"don't\", 'ma', 'no', 'wouldn', 'more', 'wasn', 'do', 'through', \"mightn't\", 'them', 'don', 'does', 'out', \"shan't\", 'weren', \"she's\", 'i', 'him', 'so', 'very', \"it's\", 'over', \"didn't\", 'myself', 'o', \"should've\", 'is', 'her', 're', 'only', 'haven', 'their', 'ours', 'did', 'not', 'those', 'had', 'about', 'its', 'hasn', 'as', 'each', 'what', 'your', 'between', 'themselves', 'from', \"couldn't\", 'at', 'these', 'a', \"doesn't\", \"needn't\", 't', 'shouldn', 'once', 'while', 'ain', 'can', 'then', 'under', 'yourselves', 'that', 'he', 'been', 'doesn', 'yourself', \"mustn't\", 'before', 'further', 'being', 'such', 'am', 'some', 'just', 'whom', 'above', 'couldn', 'or', 'below', 'they', 'needn', 've', 'own', 'too', 'by', 'which', 'most', 'same', 'will', 'won', 'doing', \"hadn't\", 'off', 'himself', 'hers'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hAGJ6OTxa1h"
      },
      "source": [
        "##Portuguese Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiKesKgwxLbV",
        "outputId": "c8e62560-e61d-42c5-b601-af7f355f4bb9"
      },
      "source": [
        "portuguese_stops = set(stopwords.words('portuguese'))\r\n",
        "\r\n",
        "print(portuguese_stops)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tiverem', 'sejamos', 'tenham', 'houvéssemos', 'meu', 'tua', 'há', 'estou', 'aquela', 'muito', 'estava', 'nossas', 'teriam', 'seria', 'estes', 'minha', 'houvéramos', 'seja', 'eles', 'lhes', 'deles', 'estivera', 'seu', 'aqueles', 'estiverem', 'seremos', 'teríamos', 'nossa', 'e', 'fora', 'tive', 'da', 'nem', 'estávamos', 'isto', 'vocês', 'mais', 'na', 'houveram', 'esta', 'essas', 'terá', 'era', 'sem', 'estivéramos', 'houveriam', 'éramos', 'estavam', 'te', 'for', 'houvemos', 'tiver', 'quem', 'como', 'hão', 'esteja', 'vos', 'tenhamos', 'teus', 'estas', 'aquilo', 'houveríamos', 'foram', 'me', 'nós', 'estivesse', 'tém', 'teria', 'está', 'suas', 'esse', 'teve', 'tu', 'até', 'dela', 'foi', 'dos', 'pelos', 'houvermos', 'estivermos', 'às', 'tivessem', 'nossos', 'tivemos', 'houverá', 'sou', 'estejam', 'fomos', 'teu', 'uma', 'para', 'estivéssemos', 'houve', 'delas', 'fossem', 'ou', 'seus', 'hajamos', 'será', 'já', 'tivéssemos', 'numa', 'esses', 'tem', 'no', 'estiveram', 'pelas', 'do', 'minhas', 'aquele', 'das', 'eu', 'houver', 'fôramos', 'seríamos', 'seriam', 'tenha', 'aos', 'estiver', 'houveremos', 'o', 'só', 'tivéramos', 'fôssemos', 'são', 'mesmo', 'pelo', 'houvesse', 'forem', 'por', 'estejamos', 'quando', 'depois', 'de', 'este', 'serei', 'as', 'estivessem', 'tivera', 'nos', 'meus', 'terão', 'que', 'tínhamos', 'havemos', 'a', 'aquelas', 'esteve', 'houvera', 'terei', 'serão', 'dele', 'isso', 'eram', 'pela', 'fui', 'lhe', 'é', 'nosso', 'os', 'fosse', 'nas', 'houverei', 'com', 'se', 'em', 'somos', 'estive', 'elas', 'teremos', 'sua', 'estamos', 'ao', 'à', 'tinha', 'tiveram', 'tenho', 'essa', 'houvessem', 'num', 'haja', 'tivesse', 'não', 'formos', 'tinham', 'qual', 'um', 'você', 'tivermos', 'hei', 'também', 'ela', 'tuas', 'houveria', 'temos', 'mas', 'sejam', 'estivemos', 'houverão', 'estão', 'houverem', 'ele', 'hajam', 'entre'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64rs29Qbxl7l"
      },
      "source": [
        "##Utilizando o stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MUX7IDWxgnK",
        "outputId": "dcc9633f-53e8-455b-f4a2-d196006d77e6"
      },
      "source": [
        "palavras = [\"Estou\", 'estudando', 'sobre', 'um', 'tema', 'interesante', 'em', 'PLN']\r\n",
        "print([palavra for palavra in palavras if palavra not in portuguese_stops])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Estou', 'estudando', 'sobre', 'tema', 'interesante', 'PLN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJr4A5tex2tt"
      },
      "source": [
        "##Stemming - Retirada de prefixos e sufixos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI_0POFUxuLO",
        "outputId": "41e88f12-13d8-4fee-9b7b-3028bff2f2c5"
      },
      "source": [
        "# Import\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.stem import LancasterStemmer\r\n",
        "\r\n",
        "\r\n",
        "# Cria o Stemmer\r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "# Aplica o Stemmer\r\n",
        "print(\"\\nPorterStemmer\")\r\n",
        "print(stemmer.stem('studing'))\r\n",
        "print(stemmer.stem('studied'))\r\n",
        "\r\n",
        "# Cria o Stemmer\r\n",
        "stemmer2 = LancasterStemmer()\r\n",
        "\r\n",
        "# Aplica o Stemmer\r\n",
        "print(\"\\nLancasterStemmer\")\r\n",
        "print(stemmer2.stem('studing'))\r\n",
        "print(stemmer2.stem('studied'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "PorterStemmer\n",
            "stude\n",
            "studi\n",
            "\n",
            "LancasterStemmer\n",
            "stud\n",
            "study\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwfG5pbax8z1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}