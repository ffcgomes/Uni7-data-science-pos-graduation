{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio de Clusterização\n",
    "\n",
    "\n",
    "Vamos trabalhar com o dataset customers. O conjunto de dados original está [disponível na UCI](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers). No nosso dataset foram removidos os atributos 'Channel' e 'Region' para facilitar a análise, pois o foco é verificarmos as seis categorias de produtos comprados pelos clientes, mas fique a vontade para trabalhar com o dado original. Após a remoção das duas variáveis citadas ficamos com o dataset final que será compostos de seis categorias importantes de produtos: Fresh, Milk, Grocery, Frozen, Detergents_Paper e Delicatessen (Perecíveis, Lacticínios, Secos e Molhados, Congelados, Limpeza/Higiene e Padaria/Frios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acesse os dados disponíveis em customers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique pré-processamento sobre os dados para criar seu dataset alvo, se você julgar necessário. \n",
    "- Dica: Você pode considerar remover as amostras que são outiliers em mais de um atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique o algoritmo [K-means](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), sobre o dataset criado. \n",
    "- Dicas: \n",
    "    * Julgue a necessidade de aplicar [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) ou não. Veja mais em nota, no final do exercício.\n",
    "    * Aplique a [normalização](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), se for utilizar o PCA\n",
    "    * Se for aplicar o PCA utilize o fit_transform() para facilitar sua vida\n",
    "    * Para reverter os valores em alguma análise considere reverter os valores utilizando o método inverse_transform() do pipeline criado\n",
    "    * Você pode criar um pipeline de transformações se quiser, veja este [exemplo](https://stackoverflow.com/questions/25475465/how-to-normalize-with-pca-and-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique o método da [silhueta](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score) e verifique a qualidade do cluster gerado\n",
    " - Dicas: No método da silhueta você deve considerar kmeans_.predict(data) como sendo os **labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Varie o número de K, hiper parâmetro do K-Means e identifique o melhor valor considerando o método da silhueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Desafio: \n",
    "   - Varie o número de K, hiper parâmetro do K-Means e identifique o melhor valor considerando o método da curva do cotovelo, [veja este exemplo](https://pythonprogramminglanguage.com/kmeans-elbow-method/). O resultado obtido foi igual ao aplicado na questão anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como você interpreta os resultados parecem favoráveis os centroídes são de fato distintos? Como você interpreta os dados com base nesta informação? \n",
    "- Dica.: Para recuperar os centroídes use kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desafio: \n",
    "   - Recupere os centroídes e faça um radar chart considerando os centroídes, [veja este exemplo](https://python-graph-gallery.com/391-radar-chart-with-several-individuals/).\n",
    "       - Dica.: Para recuperar os centroídes use kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recupere as amostras de cada cluster e faça um parallel coordinates, [veja este exemplo](https://python-graph-gallery.com/150-parallel-plot-with-pandas/) ou [este](https://jovianlin.io/data-visualization-seaborn-part-2/). Os resultados parecem favoráveis e os centroídes são de fato distintos? Como você interpreta os dados com base nesta informação?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie alguns gráficos, scatterplot do cluster, mostrando os dados definidos pelo cluster.\n",
    "- Que tal tentar marcar os centroídes neste gráfico? *P.S.: Se você criou o PCA construa o gráfico considerando variações das componentes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- É muito comum aplicar PCA para reduzir a dimensionalidade dos dados, principalmente quando trabalhamos com aprendizagem não supervisionada. Para isso é necessário interpretar o quanto as componentes explicam a variação nos dados, por exemplo, qual o número de componentes utilizar e o cumulativo total que representa as componentes sobre os dados. Também é preciso explicar como as componenentes se relaciona as variáveis originais do dado, considerando todas as amostras ou parte delas. Nesses dois sites há dicas de como compreender melhor essa interpretação [dica_1](https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/principal-components/interpret-the-results/key-results/) e [dica_2](https://newonlinecourses.science.psu.edu/stat505/node/54/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Desafio:** Se você utilizou o PCA realize a análise das componentes como valores acumulados e correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
